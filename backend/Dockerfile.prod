# ===========================================
# PRODUCTION DOCKERFILE - Backend
# Multi-stage build with native dependencies
# Feature: ai-features-reenablement
# ===========================================
#
# This Dockerfile is optimized for production deployment:
# - Uses Alpine Linux (lightweight)
# - Does NOT include ONNX runtime (incompatible with Alpine)
# - AI embeddings are handled by external Edge Function
# - AI inference via OpenAI/Anthropic APIs or AnythingLLM
#
# Environment variables for AI configuration:
# - AI_EMBEDDINGS_USE_EDGE_FUNCTION=true (default in production)
# - AI_EMBEDDINGS_USE_LOCAL=false (ONNX disabled)
# - OPENAI_API_KEY - for direct OpenAI fallback
# - SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY - for Edge Functions

# Stage 1: Dependencies & Build
FROM node:20-alpine AS builder
WORKDIR /app

# Install build dependencies for native modules (sharp, bcrypt, etc.)
# Note: We do NOT install ONNX dependencies as they don't work on Alpine
RUN apk add --no-cache \
    python3 \
    make \
    g++ \
    vips-dev \
    libc6-compat

# Install pnpm
RUN corepack enable && corepack prepare pnpm@latest --activate

# Copy package files
COPY package.json pnpm-lock.yaml* ./

# Install all dependencies (including devDependencies for build)
# Note: @xenova/transformers will be installed but won't work at runtime
# This is expected - we use Edge Function for embeddings in production
RUN pnpm install --no-frozen-lockfile || true

# Copy source code
COPY . .

# Build TypeScript
RUN pnpm build

# Remove devDependencies after build (CI=true for non-TTY environments)
RUN CI=true pnpm prune --prod

# Stage 2: Production image
FROM node:20-alpine AS production
WORKDIR /app

# Install runtime dependencies for native modules
# Note: No ONNX runtime needed - embeddings handled by Edge Function
RUN apk add --no-cache \
    vips \
    libc6-compat \
    tini \
    curl

# Create non-root user for security
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

# Copy built application
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/package.json ./package.json

# Create logs directory with proper ownership
RUN mkdir -p /app/logs && chown -R nodejs:nodejs /app/logs

# Set environment
ENV NODE_ENV=production
ENV PORT=4000

# AI Feature Configuration for Production
# Use Edge Function for embeddings (avoids ONNX/Alpine compatibility issues)
ENV AI_EMBEDDINGS_USE_EDGE_FUNCTION=true
ENV AI_EMBEDDINGS_USE_LOCAL=false

# Switch to non-root user
USER nodejs

# Expose port
EXPOSE 4000

# Health check - includes AI health endpoint
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
  CMD curl -f http://localhost:4000/health || exit 1

# Use tini as init system
ENTRYPOINT ["/sbin/tini", "--"]

# Start the application
CMD ["node", "dist/index.js"]
