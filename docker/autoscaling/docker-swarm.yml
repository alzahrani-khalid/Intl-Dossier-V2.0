version: '3.8'

services:
  backend:
    image: gastat/intl-dossier-backend:latest
    deploy:
      mode: replicated
      replicas: 2
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        monitor: 60s
        max_failure_ratio: 0.3
      rollback_config:
        parallelism: 1
        delay: 10s
        failure_action: continue
        monitor: 60s
        max_failure_ratio: 0.3
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
      labels:
        - "autoscaling.enabled=true"
        - "autoscaling.min=2"
        - "autoscaling.max=20"
        - "autoscaling.cpu_target=70"
        - "autoscaling.memory_target=80"
    environment:
      - NODE_ENV=production
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - ENABLE_GRACEFUL_DEGRADATION=true
      - MAX_POOL_SIZE=20
      - HEALTH_CHECK_INTERVAL=30s
    healthcheck:
      test: ["/docker/health-checks/backend-health.sh"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - app-network
      - monitoring-network
    volumes:
      - ./health-checks:/docker/health-checks:ro
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=backend"

  frontend:
    image: gastat/intl-dossier-frontend:latest
    deploy:
      mode: replicated
      replicas: 2
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 2
        delay: 5s
        failure_action: rollback
        monitor: 30s
        max_failure_ratio: 0.3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
      labels:
        - "autoscaling.enabled=true"
        - "autoscaling.min=2"
        - "autoscaling.max=10"
        - "autoscaling.cpu_target=70"
        - "autoscaling.memory_target=80"
    environment:
      - NODE_ENV=production
      - VITE_API_URL=${API_URL}
      - VITE_SUPABASE_URL=${SUPABASE_URL}
      - VITE_SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
    healthcheck:
      test: ["/docker/health-checks/frontend-health.sh"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - app-network
    volumes:
      - ./health-checks:/docker/health-checks:ro
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=frontend"

  autoscaler:
    image: gastat/autoscaler:latest
    deploy:
      mode: global
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    environment:
      - DOCKER_HOST=/var/run/docker.sock
      - PROMETHEUS_URL=http://prometheus:9090
      - CHECK_INTERVAL=30s
      - SCALE_UP_THRESHOLD_CPU=70
      - SCALE_UP_THRESHOLD_MEMORY=80
      - SCALE_DOWN_THRESHOLD_CPU=30
      - SCALE_DOWN_THRESHOLD_MEMORY=40
      - SCALE_UP_INCREMENT=2
      - SCALE_DOWN_INCREMENT=1
      - COOLDOWN_PERIOD=300s
      - MAX_REPLICAS=20
      - MIN_REPLICAS=2
      - ENABLE_GRACEFUL_DEGRADATION=true
      - DEGRADATION_THRESHOLD_REPLICAS=18
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - app-network
      - monitoring-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=autoscaler"

  load-balancer:
    image: nginx:alpine
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./health-checks:/docker/health-checks:ro
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=load-balancer"

networks:
  app-network:
    driver: overlay
    attachable: true
    driver_opts:
      encrypted: "true"
  
  monitoring-network:
    driver: overlay
    attachable: true
    external: true

volumes:
  backend-data:
    driver: local
  frontend-data:
    driver: local

configs:
  autoscaling-rules:
    file: ./autoscaling-rules.yml
    
secrets:
  supabase-service-key:
    external: true
  ssl-cert:
    external: true
  ssl-key:
    external: true